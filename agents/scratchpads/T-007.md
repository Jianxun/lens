# T-007 â€” Chat agent orchestration
## Context
- Streaming `/chat` endpoint; uses student portal `/v1/chat/completions` (OpenAI-compatible) with `SUPER_MIND_*` env.
- Tools: `/retrieval/peek` (top_k=100) and `/retrieval/turn`.
- Token cap 50k; fixed embedding model; cite turn_ids and histogram in response metadata.

## Scope / Allowed files
- `backend/api/chat.py`
- `backend/main.py`
- `backend/services/agent.py`

## Requirements
- Multi-pass: embed query once, peek, inspect histogram, optionally zoom (time range) with another peek, hydrate promising turns, synthesize.
- Cap hydrated turns (~<=20), truncate long texts; prefer summaries.
- Stream response; return metadata with cited turn_ids + histogram; enforce fixed embedding model; no provider/model inputs.
- Use summaries if used_turn_summary; include cited turn_ids in payload.

## DoD
- Live call returns streamed tokens; metadata includes cited turn_ids and histogram.
- Logs show tool calls and capped hydration.

